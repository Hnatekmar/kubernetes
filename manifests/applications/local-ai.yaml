apiVersion: v1
kind: Namespace
metadata:
  name: local-ai
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: local-ai
  namespace: local-ai
  labels:
    app: local-ai
spec:
  selector:
    matchLabels:
      app: local-ai
  replicas: 1
  template:
    metadata:
      labels:
        app: local-ai
      name: local-ai
    spec:
      nodeSelector:
        nvidia.com/gpu.count: "2"
      runtimeClassName: "nvidia"
      containers:
        - args:
            - --threads
            - "64"
          env:
          - name: DEBUG
            value: "true"
          name: local-ai
          image: quay.io/go-skynet/local-ai:master-cublas-cuda12
          imagePullPolicy: IfNotPresent       
          volumeMounts:
            - name: models-volume
              mountPath: /build/models
      volumes:
        - name: models-volume
          nfs:
            server: 192.168.88.25
            path: /mnt/data/k8s/local-ai
---
apiVersion: v1
kind: Service
metadata:
  name: local-ai
  namespace: local-ai
spec:
  selector:
    app: local-ai
  type: LoadBalancer
  ports:
    - protocol: TCP
      targetPort: 8080
      port: 8080
